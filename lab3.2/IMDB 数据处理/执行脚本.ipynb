{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normal_actor(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    将 IMDB 的演员数据标准化为 pd.DataFrame。每个演员及其各个作品独占一行（类似于交叉表）\n",
    "    建议之前将数据通过 VS Code 处理\n",
    "    :param file_path: \n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    source_data = pd.read_csv(\n",
    "        filepath_or_buffer=file_path,\n",
    "        header=0,\n",
    "        sep='\\t'\n",
    "    )\n",
    "    source_data.columns = ['name', 't1', 't2', 't3']\n",
    "    source_data['t1'].fillna(value='', inplace=True)\n",
    "    source_data['t2'].fillna(value='', inplace=True)\n",
    "    source_data['t3'].fillna(value='', inplace=True)\n",
    "\n",
    "    movie_list = source_data['t1'] + source_data['t2'] + source_data['t3']\n",
    "    source_data = pd.concat([source_data['name'], movie_list], axis=1)\n",
    "    source_data.columns = ['name', 'title_mix']\n",
    "\n",
    "    # source_data = source_data.iloc[:1000, :]\n",
    "\n",
    "    \"\"\"\n",
    "    使用正则表达式提取作品名、上映日期、系列名，并将他们作为新的 DataFrame\n",
    "    所以取得的结果为带 MutIndex 的 DataFrame\n",
    "    \"\"\"\n",
    "    list_name_title = []\n",
    "    for col in source_data.values:\n",
    "        if (col[0] is not np.nan):\n",
    "            names = col[0]\n",
    "            name_list = names.split(', ')\n",
    "\n",
    "        for this_name in name_list:\n",
    "\n",
    "            title_mix = col[1]\n",
    "\n",
    "            \"\"\"电影标题 字符串前一部分\"\"\"\n",
    "            title = re.search(r'^[^\\(\\{\\[]*', title_mix)\n",
    "            if title is not None:\n",
    "                title = str(title.group()[:-1])\n",
    "\n",
    "            \"\"\"上映年份 ()\"\"\"\n",
    "            year = re.search(r'(?!=\\({1})[\\d]{4}(?!=\\){1})', title_mix)\n",
    "            if year is not None:\n",
    "                year = int(year.group())\n",
    "\n",
    "            \"\"\"系列名称： {}\"\"\"\n",
    "            series_name = re.search(r'\\{(.*?)\\}', title_mix)\n",
    "            if series_name is not None:\n",
    "                series_name = str(series_name.group()[1:-1])\n",
    "\n",
    "            \"\"\"角色名称\"\"\"\n",
    "            character_name = re.search(r'\\[(.*?)\\]', title_mix)\n",
    "            if character_name is not None:\n",
    "                character_name = str(character_name.group()[1:-1])\n",
    "            # name_title.append([this_name, title, series_name, year, character_name])\n",
    "            # name_title.append([this_name, [title, series_name, year, character_name]])\n",
    "            rols = pd.DataFrame([[title, series_name, year, character_name]],\n",
    "                                columns=['title', 'series name', 'year', 'character name'])\n",
    "\n",
    "            list_name_title.append([this_name, rols])  # this_name 是 str, rols 是DataFrame\n",
    "\n",
    "    \"\"\"所以取得的结果 df_name_title 为带 MutIndex 的 DataFrame\"\"\"\n",
    "    df_name_title = pd.DataFrame(list_name_title, columns=['name', 'rols'])\n",
    "    df_name_title.sort_values(by='name', inplace=True)\n",
    "    df_name_title.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \"\"\"合并重复的 name，使其唯一。rols 中增加同一演员的信息\"\"\"\n",
    "    name = None\n",
    "    tmp_df_rols = []\n",
    "    res_list_name_rols = []\n",
    "    for i in range(df_name_title.shape[0]):\n",
    "\n",
    "        \"\"\"如果为同一人，即将作品合并的到一个 DataFrame 中\"\"\"\n",
    "        if name == df_name_title.loc[i]['name']:\n",
    "            tmp_df_rols = pd.concat([tmp_df_rols, df_name_title.loc[i]['rols']])\n",
    "\n",
    "        else:\n",
    "            \"\"\"开始下一个人\n",
    "                先将上一个人的信息写入到新的 list 中，再重置 name 和 tmp_df_rols 为当前行的内容\n",
    "            \"\"\"\n",
    "            if name is not None:\n",
    "                res_list_name_rols.append([name, tmp_df_rols])\n",
    "\n",
    "                # if name == '$haniqua':\n",
    "                #     print(tmp_df_rols)\n",
    "\n",
    "            name = df_name_title.loc[i]['name']\n",
    "            tmp_df_rols = df_name_title.loc[i]['rols']\n",
    "\n",
    "    return pd.DataFrame(data=res_list_name_rols, columns=['name', 'rols'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 女演员列表df\n",
    "print('[INFO] Start handle `data_actresses.list.txt`')\n",
    "df_actresses = normal_actor(\n",
    "    file_path='/Users/fox/Library/CloudStorage/OneDrive-PetertheGreatSt.PetersburgPolytechnicalUniversity/СПБПУ/3 '\n",
    "                'курс/6 семестр/СУБД/资料/DataSet/data_actresses.list.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 男演员列表df\n",
    "print('[INFO] Start handle `data_actors.list.txt`')\n",
    "df_actors = normal_actor(\n",
    "    file_path='/Users/fox/Library/CloudStorage/OneDrive-PetertheGreatSt.PetersburgPolytechnicalUniversity/СПБПУ/3 '\n",
    "                'курс/6 семестр/СУБД/资料/DataSet/data_actors.list.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接两个df\n",
    "print('[INFO] Start to concat two DataFrame')\n",
    "df_all_actors = pd.concat([df_actresses, df_actors], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演员信息表\n",
    "print('[INFO] Start handle `name.basics.tsv`')\n",
    "df_name_info = pd.read_csv(\n",
    "    filepath_or_buffer='/Users/fox/Library/CloudStorage/OneDrive-PetertheGreatSt'\n",
    "                        '.PetersburgPolytechnicalUniversity/СПБПУ/3 курс/6 семестр/СУБД/资料/DataSet/name.basics.tsv',\n",
    "    header=0,\n",
    "    sep='\\t'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name_info = df_name_info.iloc[:, :-1]\n",
    "df_name_info.columns = ['nconst', 'name', 'birthYear', 'deathYear', 'profession']\n",
    "\n",
    "# 处理缺失值为 None，方便转换为 JSON\n",
    "df_name_info.replace(to_replace=['\\\\N', np.nan], value=None, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[INFO] Start to merge DataFrame')\n",
    "df_all = pd.merge(left=df_name_info,\n",
    "                    right=df_all_actors,\n",
    "                    how='inner',\n",
    "                    on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[INFO] Start write to JSON file')\n",
    "df_all.to_json(\n",
    "    path_or_buf='/Users/fox/Library/CloudStorage/OneDrive-PetertheGreatSt.PetersburgPolytechnicalUniversity'\n",
    "                '/СПБПУ/3 курс/6 семестр/СУБД/资料/DataSet/df_final_all.json',\n",
    "    orient='table',\n",
    "    index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
